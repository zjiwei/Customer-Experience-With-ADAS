{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDG_SESSION_ID=10\r\n",
      "HOSTNAME=ip-172-31-95-174.ec2.internal\r\n",
      "SHELL=/bin/bash\r\n",
      "TERM=xterm-color\r\n",
      "CLICOLOR=1\r\n",
      "HISTSIZE=1000\r\n",
      "SSH_CLIENT=71.200.123.117 50950 22\r\n",
      "CONDA_SHLVL=1\r\n",
      "CONDA_PROMPT_MODIFIER=\r\n",
      "SSH_TTY=/dev/pts/0\r\n",
      "USER=ec2-user\r\n",
      "LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:\r\n",
      "CONDA_EXE=/home/ec2-user/anaconda3/bin/conda\r\n",
      "JPY_PARENT_PID=3497\r\n",
      "PAGER=cat\r\n",
      "PATH=/home/ec2-user/anaconda3/bin:/home/ec2-user/anaconda3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/ec2-user/.local/bin:/home/ec2-user/bin\r\n",
      "MAIL=/var/spool/mail/ec2-user\r\n",
      "_=/usr/bin/env\r\n",
      "CONDA_PREFIX=/home/ec2-user/anaconda3\r\n",
      "PWD=/home/ec2-user/ADAS_Driving_Safety_Practicum\r\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\r\n",
      "LANG=en_US.UTF-8\r\n",
      "HISTCONTROL=ignoredups\r\n",
      "HOME=/home/ec2-user\r\n",
      "SHLVL=2\r\n",
      "LOGNAME=ec2-user\r\n",
      "CONDA_PYTHON_EXE=/home/ec2-user/anaconda3/bin/python\r\n",
      "SSH_CONNECTION=71.200.123.117 50950 172.31.95.174 22\r\n",
      "LESSOPEN=||/usr/bin/lesspipe.sh %s\r\n",
      "CONDA_DEFAULT_ENV=base\r\n",
      "XDG_RUNTIME_DIR=/run/user/1000\r\n",
      "GIT_PAGER=cat\r\n"
     ]
    }
   ],
   "source": [
    "! env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the setting of different environment, the installing method of packages is different.\n",
    "\n",
    "\n",
    "If the system is windows, open the command prompt and type:\n",
    "\n",
    "\n",
    "\"pip install category_encoders\n",
    "\n",
    "\n",
    "pip install nltk\"\n",
    "(If the system is equipped with pip).\n",
    "\n",
    "\n",
    "Or, open the anaconda prompt and type:\n",
    "\n",
    "\n",
    "\"conda install -c conda-forge category_encoders \n",
    "\n",
    "\n",
    "conda install -c anaconda nltk \"\n",
    "(If the system is equipped with anaconda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /home/ec2-user/.local/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.19.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.23.4)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (1.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from pandas>=0.20.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from pandas>=0.20.1->category_encoders) (2018.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# For the system of Linux\n",
    "! pip install --user category_encoders\n",
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /home/ec2-user/.local/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.19.2)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from pandas>=0.20.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from pandas>=0.20.1->category_encoders) (2018.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# For the system of Mac\n",
    "! pip install category_encoders\n",
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk.stem\n",
    "from datetime import datetime as dt\n",
    "import category_encoders as ce\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. The training set are records since 2012 with manual labels, and the test set are raw records since 2012 without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the original dataset: \n",
    "https://www-odi.nhtsa.dot.gov/downloads/folders/Complaints/CMPL.txt\n",
    "\n",
    "The dataset (with manual labels) is avaiable in this address:\n",
    "https://drive.google.com/file/d/17SeAmFO6nXGVDW5-uzwXjUNWt58lZv2r/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (29,37,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('datasince2012_train+test.csv',encoding='latin-1',error_bad_lines=False)\n",
    "train = data[data['batch']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To automate the future ADAS-related complaiint identified process, the model should be able to predict the future based on current information, then a time series split is needed for the model evaluation. Before we manipulate the data, we reorder the data by the report date, so that we can perform time series split directly later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20111022\n",
       "1    20111115\n",
       "2    20120106\n",
       "3    20120130\n",
       "4    20120225\n",
       "Name: DATEA, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sort_values(by=['DATEA'])\n",
    "train['DATEA'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data['batch']==2]\n",
    "test = test.loc[(test['FAILDATE'] >= 20120101) & (test['FAILDATE'] <= 20190000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size is : (157602, 61)\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "data = pd.concat([train, test], sort = False).reset_index(drop=True)\n",
    "print(\"data size is : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2496, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155106, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Build and manipulate some features based on the existing variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that since different car brands may have the same name of their car types, we cannot uniquely identify the model of the car without combineing the car's brand and the car's model. Therefore, we combine the brand (`MAKETXT`) and the car type (`MODELTXT`) to make sure the car's model is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Age of car\n",
    "data['FAILDATE'] = pd.to_datetime(data['FAILDATE'], format = \"%Y%m%d\")\n",
    "data['AGE'] = data['FAILDATE'].apply(lambda x: int(str(x)[:4])) - data['YEARTXT']\n",
    "data['AGE'] = data['AGE'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "#The full name of model\n",
    "data['MFR_NAME'] = data['MFR_NAME'] + data['MAKETXT']\n",
    "\n",
    "## Same model name can be used in different makes\n",
    "data['MODELTXT']=data[\"MAKETXT\"].map(str) +' '+ data[\"MODELTXT\"]\n",
    "\n",
    "#To distinguish different cities with same name\n",
    "data['CITY'] = data['CITY'] + data['STATE']\n",
    "\n",
    "#The month(the influence of season etc.) and the day(work day or weekend) of faildate.\n",
    "data['FAILDATE'] = pd.to_datetime(data['FAILDATE'], format = \"%Y%m%d\")\n",
    "data['FAILMONTH'] = data['FAILDATE'].apply(lambda x : x.month)\n",
    "data['FAILWEEKDAY'] = data['FAILDATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the variables that are useful in the model.\n",
    "\n",
    "`ODINO` (NHTSA's  internal reference number) is only useful for data cleaning later, we will drop this column before we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_use = ['ODINO','MFR_NAME', 'YEARTXT', 'MAKETXT', 'MODELTXT', 'CRASH', 'FIRE', 'INJURED', 'DEATHS', 'COMPDESC', 'CITY', 'STATE', 'MILES',\n",
    "            'OCCURENCES', 'CDESCR', 'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'VEH_SPEED', 'AGE', 'FAILMONTH', 'FAILWEEKDAY','ADAS']\n",
    "data = data[cols_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set letters in the complaint and description of components lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"CDESCR\"] = data[\"CDESCR\"].apply(lambda x : str(x).lower())\n",
    "data[\"COMPDESC\"] = data[\"COMPDESC\"].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief description about the numeric variable to handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>MILES</th>\n",
       "      <th>OCCURENCES</th>\n",
       "      <th>VEH_SPEED</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FAILMONTH</th>\n",
       "      <th>FAILWEEKDAY</th>\n",
       "      <th>ADAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.576020e+05</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>56182.000000</td>\n",
       "      <td>53547.000000</td>\n",
       "      <td>1.291350e+05</td>\n",
       "      <td>43247.000000</td>\n",
       "      <td>104146.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.086542e+07</td>\n",
       "      <td>2013.748493</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>3.483297e+04</td>\n",
       "      <td>1.190348</td>\n",
       "      <td>30.761642</td>\n",
       "      <td>1.958091</td>\n",
       "      <td>6.379170</td>\n",
       "      <td>2.667942</td>\n",
       "      <td>0.029467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.886683e+05</td>\n",
       "      <td>1.559546</td>\n",
       "      <td>0.735022</td>\n",
       "      <td>0.494464</td>\n",
       "      <td>8.532986e+04</td>\n",
       "      <td>1.220660</td>\n",
       "      <td>29.439233</td>\n",
       "      <td>1.715441</td>\n",
       "      <td>3.321202</td>\n",
       "      <td>1.918884</td>\n",
       "      <td>0.169111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.033260e+07</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.070619e+07</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.090314e+07</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.300000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.103162e+07</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.162800e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.112407e+07</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000443e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ODINO        YEARTXT       INJURED        DEATHS         MILES  \\\n",
       "count  1.576020e+05  157602.000000  56182.000000  53547.000000  1.291350e+05   \n",
       "mean   1.086542e+07    2013.748493      0.183404      0.008927  3.483297e+04   \n",
       "std    1.886683e+05       1.559546      0.735022      0.494464  8.532986e+04   \n",
       "min    1.033260e+07    2012.000000      0.000000      0.000000  0.000000e+00   \n",
       "25%    1.070619e+07    2012.000000      0.000000      0.000000  5.000000e+03   \n",
       "50%    1.090314e+07    2013.000000      0.000000      0.000000  2.300000e+04   \n",
       "75%    1.103162e+07    2015.000000      0.000000      0.000000  5.162800e+04   \n",
       "max    1.112407e+07    2018.000000     99.000000     99.000000  9.000443e+06   \n",
       "\n",
       "         OCCURENCES      VEH_SPEED            AGE      FAILMONTH  \\\n",
       "count  43247.000000  104146.000000  157602.000000  157602.000000   \n",
       "mean       1.190348      30.761642       1.958091       6.379170   \n",
       "std        1.220660      29.439233       1.715441       3.321202   \n",
       "min        0.000000       0.000000       0.000000       1.000000   \n",
       "25%        1.000000       5.000000       0.000000       4.000000   \n",
       "50%        1.000000      30.000000       2.000000       6.000000   \n",
       "75%        1.000000      55.000000       3.000000       9.000000   \n",
       "max      100.000000     999.000000       6.000000      12.000000   \n",
       "\n",
       "         FAILWEEKDAY           ADAS  \n",
       "count  157602.000000  157602.000000  \n",
       "mean        2.667942       0.029467  \n",
       "std         1.918884       0.169111  \n",
       "min         0.000000       0.000000  \n",
       "25%         1.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%         4.000000       0.000000  \n",
       "max         6.000000       1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find outliers in INJURED (number of people injured in the accident), DEATHS (number of people dead in the accident), OCCURENCES (number of the mulfunction condition occured), VEH_SPEED (the speed of the car when the accident happened).\n",
    "\n",
    "- After we sort the records by 'INJURED' and 'DEATHS', we find the record having 99 in 'INJURED' and 'DEATHS' are from one complaint, and record having 50 in 'INJURED' and 'DEATHS' are from another complaint. When we look at the content of the complaints, they are not about the desciptions of the accident, then we set the 'INJURED' and 'DEATHS' in these two records(ODINO 11101150 and 11101553) as missing.\n",
    "\n",
    "- Next, we inspect the outliers in 'OCCURENCES', we find in these records, most complaints mention the approximate occurrence times, so we keep the original values.\n",
    "\n",
    "- Finally we check the outliers in 'VEH_SPEED', we find for those records with speed greater than 140 mph, most of them are filled incorrectly based on the content of the complaint. So we set all VEH_SPEED' greater than 140 as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'INJURED': [50,99], 'DEATHS': [50,99]}, np.nan)\n",
    "data['VEH_SPEED'] = data['VEH_SPEED'].apply(lambda x: x if x <= 140 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODINO                  0\n",
       "MFR_NAME               0\n",
       "YEARTXT                0\n",
       "MAKETXT                0\n",
       "MODELTXT               0\n",
       "CRASH                  0\n",
       "FIRE                   0\n",
       "INJURED           101422\n",
       "DEATHS            104057\n",
       "COMPDESC               0\n",
       "CITY                   7\n",
       "STATE                  0\n",
       "MILES              28467\n",
       "OCCURENCES        114355\n",
       "CDESCR                 0\n",
       "ANTI_BRAKES_YN       339\n",
       "CRUISE_CONT_YN       339\n",
       "VEH_SPEED          53564\n",
       "AGE                    0\n",
       "FAILMONTH              0\n",
       "FAILWEEKDAY            0\n",
       "ADAS                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For `INJURED` and `DEATHS`, we use 0 to fill the null value.\n",
    "- For `CITY`, we use a string to fill the null value.\n",
    "- For `MILES` (the miles of the car), we fill the null value with median of the `MILES` in the training set, then add some random noise from the normal distribution ranged from 0 to 3000 (we decide the noise range based on the scale of this column).\n",
    "- For `OCCURENCES`, we use 1 to fill the null value.\n",
    "- For `VEH_SPEED`, we fill the null value with the median of the `VEH_SPEED`, then add some random noise from the normal distribution ranged from 0 to 10.\n",
    "- For `MEDICAL_ATTN` (Was medical attention required) and `VEHICLES_TOWED_YN` (Was vehicle towed), since they are binary of \"Y\" (yes) and \"N\" (no), we decide to use \"N\" to fill the null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill na\n",
    "data['INJURED'] = data['INJURED'].fillna(0)\n",
    "data['DEATHS'] = data['DEATHS'].fillna(0)\n",
    "data['CITY'] = data['CITY'].fillna('NA')\n",
    "data['MILES'] = data['MILES'].fillna(data[:ntrain]['MILES'].median())+np.random.normal(0,3000)\n",
    "data['VEH_SPEED'] = data['VEH_SPEED'].fillna(data[:ntrain]['VEH_SPEED'].median()) + np.random.normal(0,10)\n",
    "data['OCCURENCES'] = data['OCCURENCES'].fillna(1)\n",
    "data['ANTI_BRAKES_YN'] = data['ANTI_BRAKES_YN'].fillna('N')\n",
    "data['CRUISE_CONT_YN'] = data['CRUISE_CONT_YN'].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data have no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we handle duplicated rows. \n",
    "Base on the description for the dataset, we notice when a consumer reports an accident, it will create multiple records in the dataset if the consumer reports the issue on multiple components, which means we have duplicated rows but the COMPDESC(component description) are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>MFR_NAME</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>MAKETXT</th>\n",
       "      <th>MODELTXT</th>\n",
       "      <th>CRASH</th>\n",
       "      <th>FIRE</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>COMPDESC</th>\n",
       "      <th>...</th>\n",
       "      <th>MILES</th>\n",
       "      <th>OCCURENCES</th>\n",
       "      <th>CDESCR</th>\n",
       "      <th>ANTI_BRAKES_YN</th>\n",
       "      <th>CRUISE_CONT_YN</th>\n",
       "      <th>VEH_SPEED</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FAILMONTH</th>\n",
       "      <th>FAILWEEKDAY</th>\n",
       "      <th>ADAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84296</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>structure:body</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84297</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>air bags</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84298</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seats</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84299</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seat belts</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODINO                MFR_NAME  YEARTXT MAKETXT      MODELTXT CRASH  \\\n",
       "84296  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84297  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84298  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84299  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "\n",
       "      FIRE  INJURED  DEATHS        COMPDESC  ...           MILES OCCURENCES  \\\n",
       "84296    N      9.0     9.0  structure:body  ...   128895.290775        1.0   \n",
       "84297    N      9.0     9.0        air bags  ...   128895.290775        1.0   \n",
       "84298    N      9.0     9.0           seats  ...   128895.290775        1.0   \n",
       "84299    N      9.0     9.0      seat belts  ...   128895.290775        1.0   \n",
       "\n",
       "                                                  CDESCR  ANTI_BRAKES_YN  \\\n",
       "84296  i had rented the ford transit from enterprise ...               N   \n",
       "84297  i had rented the ford transit from enterprise ...               N   \n",
       "84298  i had rented the ford transit from enterprise ...               N   \n",
       "84299  i had rented the ford transit from enterprise ...               N   \n",
       "\n",
       "      CRUISE_CONT_YN  VEH_SPEED AGE  FAILMONTH  FAILWEEKDAY  ADAS  \n",
       "84296              N  25.728497   0         11            3     0  \n",
       "84297              N  25.728497   0         11            3     0  \n",
       "84298              N  25.728497   0         11            3     0  \n",
       "84299              N  25.728497   0         11            3     0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example for duplicated rows, but the COMPDESC is different\n",
    "data[data.ODINO==10915684]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to change the format of the dataset. We can create the dummies variables for COMPDESC and merge those duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows\n",
    "unique_odino_df = data.drop(columns = 'COMPDESC').drop_duplicates('ODINO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65                                                 air bags\n",
       "79887                      air bags: air bag control module\n",
       "2413                                  air bags: clockspring\n",
       "134291    air bags: occupant classification system - ocs...\n",
       "2778                                       air bags:frontal\n",
       "Name: COMPDESC, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values in COMPDESC\n",
    "comp = data['COMPDESC'].drop_duplicates().sort_values()\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see for `air bags: air bag control module`, it should be a part of `air bag`. If we simply get dummies variables based on the values in COMPDESC, then there are rows having 1 in  `air bags: air bag control module` but having 0 in `air bags`. To solve this problem, we split the component combination into individual components. For each row, if the an individual component was included in the combination, then we set individual component to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = []\n",
    "# for each level in COMPDESC\n",
    "for x in comp:\n",
    "    # split the component combination\n",
    "    x_split = x.split(\":\")\n",
    "    for i in x_split:\n",
    "            i = i.strip()\n",
    "            # append the individual component to the list\n",
    "            if i not in comp_list:\n",
    "                comp_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>COMPDESC</th>\n",
       "      <th>comp_air bags</th>\n",
       "      <th>comp_air bag control module</th>\n",
       "      <th>comp_clockspring</th>\n",
       "      <th>comp_occupant classification system - ocs (front passenger)</th>\n",
       "      <th>comp_frontal</th>\n",
       "      <th>comp_driver side inflator module</th>\n",
       "      <th>comp_sensor/control module</th>\n",
       "      <th>comp_knee bolster</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10432460</td>\n",
       "      <td>steering</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10435675</td>\n",
       "      <td>vehicle speed control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10442757</td>\n",
       "      <td>service brakes, hydraulic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10445803</td>\n",
       "      <td>electrical system</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10449316</td>\n",
       "      <td>engine and engine cooling</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ODINO                   COMPDESC  comp_air bags  \\\n",
       "0  10432460                   steering              0   \n",
       "1  10435675      vehicle speed control              0   \n",
       "2  10442757  service brakes, hydraulic              0   \n",
       "3  10445803          electrical system              0   \n",
       "4  10449316  engine and engine cooling              0   \n",
       "\n",
       "   comp_air bag control module  comp_clockspring  \\\n",
       "0                            0                 0   \n",
       "1                            0                 0   \n",
       "2                            0                 0   \n",
       "3                            0                 0   \n",
       "4                            0                 0   \n",
       "\n",
       "   comp_occupant classification system - ocs (front passenger)  comp_frontal  \\\n",
       "0                                                  0                       0   \n",
       "1                                                  0                       0   \n",
       "2                                                  0                       0   \n",
       "3                                                  0                       0   \n",
       "4                                                  0                       0   \n",
       "\n",
       "   comp_driver side inflator module  comp_sensor/control module  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   comp_knee bolster    ...     comp_rearview mirrors/devices  comp_exterior  \\\n",
       "0                  0    ...                                 0              0   \n",
       "1                  0    ...                                 0              0   \n",
       "2                  0    ...                                 0              0   \n",
       "3                  0    ...                                 0              0   \n",
       "4                  0    ...                                 0              0   \n",
       "\n",
       "   comp_interior  comp_sun roof assembly  comp_windshield wiper/washer  \\\n",
       "0              0                       0                             0   \n",
       "1              0                       0                             0   \n",
       "2              0                       0                             0   \n",
       "3              0                       0                             0   \n",
       "4              0                       0                             0   \n",
       "\n",
       "   comp_wheels  comp_cap/cover/hub  comp_center section  comp_lugs/nuts/bolts  \\\n",
       "0            0                   0                    0                     0   \n",
       "1            0                   0                    0                     0   \n",
       "2            0                   0                    0                     0   \n",
       "3            0                   0                    0                     0   \n",
       "4            0                   0                    0                     0   \n",
       "\n",
       "   comp_rim  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop exact same rows, keep rows have same ODINO but different COMPDESC\n",
    "comp_df = data[[\"ODINO\", \"COMPDESC\"]].drop_duplicates()\n",
    "\n",
    "for col in comp_list:\n",
    "    # create a new binary column for each component\n",
    "    comp_df[col] = 0\n",
    "    for i in comp_df.index:\n",
    "        # set the value to 1 if the individual component is included in COMPDESC(component combination)\n",
    "        if col in comp_df.loc[i, \"COMPDESC\"]:\n",
    "            comp_df.loc[i, col] = 1\n",
    "    # rename the column for the convenience of further analysis\n",
    "    comp_df = comp_df.rename(columns={col:\"comp_\"+col})\n",
    "    \n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the information for duplicated rows, we group those rows, sum up all new created binary columns within the group, then delete duplicated rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>comp_air bags</th>\n",
       "      <th>comp_air bag control module</th>\n",
       "      <th>comp_clockspring</th>\n",
       "      <th>comp_occupant classification system - ocs (front passenger)</th>\n",
       "      <th>comp_frontal</th>\n",
       "      <th>comp_driver side inflator module</th>\n",
       "      <th>comp_sensor/control module</th>\n",
       "      <th>comp_knee bolster</th>\n",
       "      <th>comp_on-off switch assembly</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10332595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10432460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10435675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10442321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10442757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ODINO  comp_air bags  comp_air bag control module  comp_clockspring  \\\n",
       "0  10332595              0                            0                 0   \n",
       "1  10432460              0                            0                 0   \n",
       "2  10435675              0                            0                 0   \n",
       "3  10442321              0                            0                 0   \n",
       "4  10442757              0                            0                 0   \n",
       "\n",
       "   comp_occupant classification system - ocs (front passenger)  comp_frontal  \\\n",
       "0                                                  0                       0   \n",
       "1                                                  0                       0   \n",
       "2                                                  0                       0   \n",
       "3                                                  0                       0   \n",
       "4                                                  0                       0   \n",
       "\n",
       "   comp_driver side inflator module  comp_sensor/control module  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   comp_knee bolster  comp_on-off switch assembly    ...     \\\n",
       "0                  0                            0    ...      \n",
       "1                  0                            0    ...      \n",
       "2                  0                            0    ...      \n",
       "3                  0                            0    ...      \n",
       "4                  0                            0    ...      \n",
       "\n",
       "   comp_rearview mirrors/devices  comp_exterior  comp_interior  \\\n",
       "0                              0              0              0   \n",
       "1                              0              0              0   \n",
       "2                              0              0              0   \n",
       "3                              0              0              0   \n",
       "4                              0              0              0   \n",
       "\n",
       "   comp_sun roof assembly  comp_windshield wiper/washer  comp_wheels  \\\n",
       "0                       0                             0            0   \n",
       "1                       0                             0            0   \n",
       "2                       0                             0            0   \n",
       "3                       0                             0            0   \n",
       "4                       0                             0            0   \n",
       "\n",
       "   comp_cap/cover/hub  comp_center section  comp_lugs/nuts/bolts  comp_rim  \n",
       "0                   0                    0                     0         0  \n",
       "1                   0                    0                     0         0  \n",
       "2                   0                    0                     0         0  \n",
       "3                   0                    0                     0         0  \n",
       "4                   0                    0                     0         0  \n",
       "\n",
       "[5 rows x 283 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum up all new created binary columns\n",
    "comp_df = comp_df.groupby('ODINO').sum().reset_index()\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the aggregated columns back to the remaining dataframe \n",
    "clean_data = pd.merge(unique_odino_df, comp_df, how = \"left\", on = 'ODINO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>MFR_NAME</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>MAKETXT</th>\n",
       "      <th>MODELTXT</th>\n",
       "      <th>CRASH</th>\n",
       "      <th>FIRE</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60076</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>CENTERTX</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODINO                MFR_NAME  YEARTXT MAKETXT      MODELTXT CRASH  \\\n",
       "60076  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "\n",
       "      FIRE  INJURED  DEATHS      CITY    ...    comp_rearview mirrors/devices  \\\n",
       "60076    N      9.0     9.0  CENTERTX    ...                                0   \n",
       "\n",
       "       comp_exterior  comp_interior comp_sun roof assembly  \\\n",
       "60076              0              0                      0   \n",
       "\n",
       "      comp_windshield wiper/washer comp_wheels  comp_cap/cover/hub  \\\n",
       "60076                            0           0                   0   \n",
       "\n",
       "       comp_center section  comp_lugs/nuts/bolts  comp_rim  \n",
       "60076                    0                     0         0  \n",
       "\n",
       "[1 rows x 303 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the example found before is fixed\n",
    "clean_data.loc[clean_data[\"ODINO\"] == 10915684]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data back to training set and test set, the data is ready for model building now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the index for the training set since we delete rows\n",
    "ntrain = data[:ntrain]['ODINO'].nunique()\n",
    "\n",
    "adas = clean_data[:ntrain]['ADAS']\n",
    "df = clean_data.drop(columns = ['ODINO','ADAS'])\n",
    "train = df[:ntrain]\n",
    "test = df[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with sklearn pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cross validation strategy. Time series split allows the model to simulate the forecasting process based on current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv=StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "cv = TimeSeriesSplit(n_splits=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize different features, we are going to extract these feaures and run different transformers on them later.\n",
    "- For text features, we count the tf-idf value for the words.\n",
    "- For categorical features, we run one-hot encoding.\n",
    "- For numeric features(including the binary columns for COMPDESC), we delete empty columns to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_feats=['YEARTXT','FAILMONTH','FAILWEEKDAY']\n",
    "text_feat= ['CDESCR']\n",
    "cat_feats = set(train.dtypes[train.dtypes == \"object\"].index) - set(text_feat) | set(label_feats)\n",
    "num_feats = set(train.dtypes[train.dtypes != \"object\"].index) - set(label_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FactorExtractor are used to extract categorical features, text feature and numeric features individually in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorExtractor(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    In: pd.DataFrame\n",
    "        Column in that Frame\n",
    "    Out: pd.Series\n",
    "    \n",
    "    In: pd.DataFrame\n",
    "        list of Columns in that Frame\n",
    "    Out: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def transform(self, data):\n",
    "        return data.loc[:,self.factor]\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we get dummies variables for COMPDESC on the whole dataset, it is possible that when we train the model, there are empty columns in the training set, because information are leaked from test set to training set. To avoid data leakage, we have to delete these empty columns in each cross - validation loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDeleter(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Delete columns with all - zero values in training set.\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, data):\n",
    "        return data.drop(columns = self.col)\n",
    "    \n",
    "    def fit(self, data, *_):\n",
    "        self.col = data.columns[(data == 0).all()]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder are used to encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols = cat_feats,return_df=False,use_cat_names=True,handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize NMF for non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize tfidf_vectorizer to apply stemming and english stop words on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow stemming in Sklearn TfidfVectorizer\n",
    "en_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([en_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "tfidf_vectorizer= StemmedTfidfVectorizer(analyzer=\"word\", stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract categorical features, text feature and numeric features individually, run different transformer on these features within the pipeline, then we use feature union to merger these features back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "catpipe=Pipeline([ ('cat_extractor',FactorExtractor(cat_feats)),\n",
    "                   ('encode', encoder)\n",
    "                  ])\n",
    "\n",
    "numpipe=Pipeline([ ('feat_extractor',FactorExtractor(num_feats)),\n",
    "                   ('deleter', ColumnDeleter())\n",
    "                  ])\n",
    "\n",
    "# extract the value in the list, so we can pass a pd series to the vectorizer, instead of a 1-column dataframe\n",
    "textpipe=Pipeline([('text_extractor', FactorExtractor(text_feat[0])),  \n",
    "                   ('tfidf',tfidf_vectorizer)\n",
    "                  ])\n",
    "\n",
    "feat_union=FeatureUnion([('text',textpipe),\n",
    "                         ('num',numpipe),\n",
    "                         ('cat',catpipe)\n",
    "                        ])\n",
    "\n",
    "\n",
    "pipe=Pipeline([ ('union',feat_union),\n",
    "                ('clf',gbm)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper parameters to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist=dict(union__text__tfidf__max_df=[s/float(100) for s in range(50, 90, 5)],\n",
    "                union__text__tfidf__min_df=range(1,15),\n",
    "                union__text__tfidf__ngram_range=[(1,3),(1,4),(1,5)],\n",
    "                clf__loss=['deviance','exponential'],\n",
    "                clf__n_estimators=[100,200],\n",
    "                clf__subsample=[s/float(100) for s in range(50, 101, 2)],\n",
    "                clf__max_features=[s/float(100) for s in range(1, 80, 3)],\n",
    "                clf__max_depth=range(2,5),\n",
    "                clf__min_samples_leaf=range(5,30,3),\n",
    "                clf__min_samples_split=range(5,30),\n",
    "                clf__random_state =range(1,10))\n",
    "\n",
    "model=RandomizedSearchCV(pipe,param_dist,cv=cv,n_iter=30,random_state=1,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "          error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('text_extractor', FactorExtractor(factor='CDESCR')), ('tfidf', StemmedTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "            dtype=<class 'numpy.int64'>, encoding='...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=30, n_jobs=1,\n",
       "          param_distributions={'union__text__tfidf__max_df': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85], 'union__text__tfidf__min_df': range(1, 15), 'union__text__tfidf__ngram_range': [(1, 3), (1, 4), (1, 5)], 'clf__loss': ['deviance', 'exponential'], 'clf__n_estimators': [100, 200], 'clf__subsample': [0.5,...s_leaf': range(5, 30, 3), 'clf__min_samples_split': range(5, 30), 'clf__random_state': range(1, 10)},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,adas.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90926258733756"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'union__text__tfidf__ngram_range': (1, 5),\n",
       " 'union__text__tfidf__min_df': 1,\n",
       " 'union__text__tfidf__max_df': 0.7,\n",
       " 'clf__subsample': 0.88,\n",
       " 'clf__random_state': 8,\n",
       " 'clf__n_estimators': 200,\n",
       " 'clf__min_samples_split': 24,\n",
       " 'clf__min_samples_leaf': 5,\n",
       " 'clf__max_features': 0.43,\n",
       " 'clf__max_depth': 2,\n",
       " 'clf__loss': 'exponential'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the feature importance, we need to extract the feature names from each part of feature union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "textpipe_names = model.best_estimator_.named_steps['union'].transformer_list[0][1].named_steps['tfidf'].get_feature_names()\n",
    "numpipe_names = model.best_estimator_.named_steps['union'].transformer_list[1][1].fit_transform(train).columns\n",
    "catpipe_names = model.best_estimator_.named_steps['union'].transformer_list[2][1].named_steps['encode'].get_dummies(train[list(cat_feats)]).columns\n",
    "col_names = list(textpipe_names) + list(catpipe_names) + list(numpipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model.best_estimator_.named_steps['clf'].feature_importances_,\n",
    "                                   index = col_names,\n",
    "                                   columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>camera</th>\n",
       "      <td>0.108638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park assist</th>\n",
       "      <td>0.073053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collis</th>\n",
       "      <td>0.066633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automatic brak</th>\n",
       "      <td>0.063792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency brak</th>\n",
       "      <td>0.060970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blind spot</th>\n",
       "      <td>0.048711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapt</th>\n",
       "      <td>0.039915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonom</th>\n",
       "      <td>0.035180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lane assist</th>\n",
       "      <td>0.027591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward collis</th>\n",
       "      <td>0.025840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.024366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return vehicl</th>\n",
       "      <td>0.023752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive cruis</th>\n",
       "      <td>0.022978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brake</th>\n",
       "      <td>0.022632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>0.022172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capabl</th>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitig</th>\n",
       "      <td>0.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerg</th>\n",
       "      <td>0.016842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot</th>\n",
       "      <td>0.016716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.016621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance\n",
       "camera            0.108638\n",
       "park assist       0.073053\n",
       "collis            0.066633\n",
       "automatic brak    0.063792\n",
       "emergency brak    0.060970\n",
       "blind spot        0.048711\n",
       "adapt             0.039915\n",
       "autonom           0.035180\n",
       "lane assist       0.027591\n",
       "forward collis    0.025840\n",
       "acc               0.024366\n",
       "return vehicl     0.023752\n",
       "adaptive cruis    0.022978\n",
       "brake             0.022632\n",
       "dont              0.022172\n",
       "capabl            0.017911\n",
       "mitig             0.017280\n",
       "emerg             0.016842\n",
       "spot              0.016716\n",
       "pre               0.016621"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110532, 301)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1 created.\n",
      "part 1 predicted\n",
      "part 2 created.\n",
      "part 2 predicted\n",
      "part 3 created.\n",
      "part 3 predicted\n",
      "part 4 created.\n",
      "part 4 predicted\n",
      "part 5 created.\n",
      "part 5 predicted\n",
      "part 6 created.\n",
      "part 6 predicted\n"
     ]
    }
   ],
   "source": [
    "# test set is too big, it will raise error on prediction\n",
    "# split the test set to serveral data sets for prediction\n",
    "test_dict = {}\n",
    "pred_dict = {}\n",
    "for i in range(1, 7):\n",
    "    test_dict['test' + str(i)] = test[20000 * (i - 1):20000 * i]\n",
    "    print('part ' + str(i) + ' created.')\n",
    "    pred_dict['prediction' + str(i)] = model.predict(test_dict['test' + str(i)])\n",
    "    print('part ' + str(i) + ' predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction = pred_dict['prediction1']\n",
    "for i in range(2, 7):\n",
    "    prediction = np.concatenate((prediction, pred_dict['prediction' + str(i)]), axis=None)\n",
    "\n",
    "test['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('datasince2012_test_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 100 samples which have positive prediciton, then we manually review these results to test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=test[test['prediction']==1].sample(n=100,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.to_csv('datasince2012_test_predicted_sample100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the test set with training set, then we get all data labeled after 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['prediction'] = adas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata=pd.concat([train,test])\n",
    "alldata.to_csv('datasince2012_all_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 302)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110532, 302)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112966, 302)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data2 = pd.concat([clean_data, alldata['prediction']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data2.to_csv('datasince2012_clean_data_all_labeled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
